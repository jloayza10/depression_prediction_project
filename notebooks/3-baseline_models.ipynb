{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1734a14-7a73-4b61-aef4-c0a32bdc9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score, cohen_kappa_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate\n",
    "from scipy.stats import loguniform\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "import importlib\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fc37aa-56bf-4712-a1a6-185330117b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a120f682-3685-4435-a436-d265c7748abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140000e7-4238-442b-bbb8-29961e21885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scoring_and_evaluation\n",
    "import feature_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbef6a8-a07e-4b8a-ac76-f01d73d92292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'feature_preprocessing' from 'C:\\\\Users\\\\Jorge\\\\Desktop\\\\Data_Science\\\\Projects\\\\Depression_repo\\\\notebooks\\\\../scripts\\\\feature_preprocessing.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(scoring_and_evaluation)\n",
    "importlib.reload(feature_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba66986-1998-449d-884f-80dd35170c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_list_from_pkl\n",
    "from scoring_and_evaluation import loguniform_int, adjacent_accuracy_score, randomized_search_and_cv\n",
    "from feature_preprocessing import preprocess_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1d543-f2d1-47fe-b510-6383f5181605",
   "metadata": {},
   "source": [
    "Column name lists and dataframe information loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03e5a6e-4b0f-4014-9618-4723ae6b5790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_input</td>\n",
       "      <td>(33320, 127)</td>\n",
       "      <td>Complete cleaned input data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_study</td>\n",
       "      <td>(9227, 87)</td>\n",
       "      <td>Cleaned + filtered input data based on paper's specifications + deleted features missing &gt;10% data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data</td>\n",
       "      <td>(9227, 83)</td>\n",
       "      <td>df_study without target variables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_cat</td>\n",
       "      <td>(9227,)</td>\n",
       "      <td>target phq9_cat_end from df_study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_train</td>\n",
       "      <td>(8304, 83)</td>\n",
       "      <td>90% of df data for model training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data_test</td>\n",
       "      <td>(923, 83)</td>\n",
       "      <td>10% of df data for model testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>target_train</td>\n",
       "      <td>(8304,)</td>\n",
       "      <td>90% of df target_cat for model training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>target_test</td>\n",
       "      <td>(923,)</td>\n",
       "      <td>10% of df target_cat for model testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X_train_full</td>\n",
       "      <td>(8304, 143)</td>\n",
       "      <td>data_train df with all additional feature engineering columns (+50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X_train_full_preprocessed</td>\n",
       "      <td>(8304, 145)</td>\n",
       "      <td>X_train_full df with preprocessing (imputation, scaling...)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data_add_features</td>\n",
       "      <td>(9227, 143)</td>\n",
       "      <td>data df with additional features (+50)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_path = '../data/lists/'\n",
    "base_feats_cat = load_list_from_pkl(list_path+'base_feats_cat.pkl')\n",
    "base_feats_num = load_list_from_pkl(list_path+'base_feats_num.pkl')\n",
    "stats_cols = load_list_from_pkl(list_path+'stats_cols.pkl')\n",
    "metadata_file = '../data/processed/metadata.csv'\n",
    "df_path = '../data/processed/'\n",
    "metadata_df = pd.read_csv(metadata_file)\n",
    "display(HTML(metadata_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba33977-79dc-440b-b9ec-d52978229bd4",
   "metadata": {},
   "source": [
    "Dataframe loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636bad72-47e1-47c1-8bca-af8e684e0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r'../data/processed/data')\n",
    "data_add_features = pd.read_pickle(r'../data/processed/data_add_features')\n",
    "target_cat = pd.read_pickle(r'../data/processed/target_cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84a66f-0f37-4f02-8a0a-7a101b167260",
   "metadata": {},
   "source": [
    "Scorer creation, which allows to compare the results with the results obtained by the authors in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f84f913-3621-419c-9bb5-7a419941e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_f1 = make_scorer(f1_score, greater_is_better=True, average=\"weighted\")\n",
    "adjacent_accuracy = make_scorer(adjacent_accuracy_score, greater_is_better=True)\n",
    "cohen_kappa = make_scorer(cohen_kappa_score, greater_is_better=True, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510e8775-6987-49a4-b755-496e0e2a866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'custom_f1': custom_f1,\n",
    "           'adjacent_accuracy_score': adjacent_accuracy,\n",
    "           'cohen_kappa_score': cohen_kappa\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f94224-b96d-42de-b4a0-87f513961b76",
   "metadata": {},
   "source": [
    "# Modeling: Logistic Regression, HistGradientBoostingClassifier and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad586a6-84f3-42f6-9b77-610af2ae0c8c",
   "metadata": {},
   "source": [
    "As a baseline, a `LogisticRegression()` model is used, with 3 hyperparameters to be tuned while also performing a generalization scoring. These two steps are performed through a nested cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be23e1b-85df-4dca-976c-6dd92ea7c309",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1ee2e2-2c29-4431-9c6c-a0902ef6c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1adbd96c-22eb-4db4-9597-7c3be317a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"max_iter\": loguniform_int(1000, 5000),\n",
    "    \"C\": loguniform(0.001, 1),\n",
    "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c40754-807f-443e-9f97-82a611637a51",
   "metadata": {},
   "source": [
    "The nested cross-validation procedure allows to optimize hyperparameters (in this case with `RandomizedSearchCV`) while testing the prediction generalization capabilities of a model using a k-fold cross-validation (with `cross_validate`). The hyperparameter search is therefore performed on each of the folds of the outer splits of the `cross_validate` step. The idea of this procedure is to avoid an optimistic bias on the performance evaluation and/or avoid overfitting.\n",
    "The `RandomizedSearchCV` allows for a stochastic search of the hyperparameter values and combinations by specifying a distribution of each hyperparameter value that is searched. An inner cross-validation is performed where the data is split according to the value of `cv`, and in each split there are `n_iter` model fittings with different hyperparameter combinations.\n",
    "Then, for each fold in the outer `cross_validate`, the best model with the hyperparameter values selected is chosen to score its generalization performance. the outer cross-validation allows to score the model on data it has not been trained on. One of the drawbacks of this methodology is that the number of model fitting can quickly increase significantly, which translates into more comkputing resources and time. <br>\n",
    "Given that we are using multiple scorers, the `refit` parameter is used with the f1 scorer. This allows to use that specific scorer to find the best parameters. This is a different methodology than used in the paper, where the authors used the Cohen-Kappa score as the one to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c05afb-8719-47de-aa0d-0a835ccc6315",
   "metadata": {},
   "source": [
    "For this baseline study, we will also compare the performance of the models on 3 datasets: the original dataset with some basic preprocessing (preprocess_dataframe(data)), the same dataset with all additional features from the feature engineering process (preprocess_dataframe(data_add_features)) and finally the original dataset with only some pre-selected basic categorical and numerical features (preprocess_dataframe(data[base_feats_cat+base_feats_num]))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8f017-e26d-4ec4-a2a2-da44d21f71ae",
   "metadata": {},
   "source": [
    "To observe the results, the function [randomized_search_and_cv()](https://github.com/jloayza10/depression_prediction_project/blob/main/scripts/scoring_and_evaluation.py) is used. Both the inner and outher cross-validations use a 5-fold split. The function prints the generalization scores by averaging the 5 results obtained on each of the outer folds. Also, for each of these 5 folds, the inner cross-validation performs 5 splits (80%-20% of the remaining data) and performs 20 iterations to find the best hyperparameter values. These results are also printed.   <br>\n",
    "If we look more in detail the hyperparameter tuning step for each of the 5 folds of the outer cross-validation, the results are presented below. This allows to see if the chosen hyperparameter values are always similar or if the search has varied a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "618c89a7-2ba3-49e2-b190-04374e07c120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LogisticRegression()' generalization scores:\n",
      "Weighted f1: 0.418 +/- 0.010\n",
      "Cohen Kappa: 0.424 +/- 0.017\n",
      "Adjacent Accuracy: 0.825 +/- 0.008\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.4161621108196994\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 2 with a best result of 0.4099172204380227\n",
      "{'C': 0.11938997108268634, 'max_iter': 4097, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 3 with a best result of 0.4141469441333224\n",
      "{'C': 0.11938997108268634, 'max_iter': 4097, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 4 with a best result of 0.40714033900214497\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 5 with a best result of 0.4099028800053205\n",
      "{'C': 0.11938997108268634, 'max_iter': 4097, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "cv_results_data = randomized_search_and_cv(model_LR, param_distributions, preprocess_dataframe(data), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722d38e-d913-4397-b7f8-d77b43f69413",
   "metadata": {},
   "source": [
    "Results show that 3 out of the 5 models converged to the same hyperparameters, while the other 2 converged to the same solver but different C and max_iter values. However, all f1-scores are almost equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "67d9a4c5-1d9e-4fec-a4dc-7d9ef110aa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LogisticRegression()' generalization scores:\n",
      "Weighted f1: 0.420 +/- 0.011\n",
      "Cohen Kappa: 0.414 +/- 0.019\n",
      "Adjacent Accuracy: 0.825 +/- 0.006\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.4149053137484504\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 2 with a best result of 0.41511789167224966\n",
      "{'C': 0.5519326346081438, 'max_iter': 2087, 'solver': 'lbfgs'}\n",
      "Best hyperparameters for fold 3 with a best result of 0.41353635153989377\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 4 with a best result of 0.41478763223582205\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 5 with a best result of 0.41421443827724724\n",
      "{'C': 0.11938997108268634, 'max_iter': 4097, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "cv_results_base = randomized_search_and_cv(model_LR, param_distributions, preprocess_dataframe(data[base_feats_cat+base_feats_num]), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "09b2fd2c-4994-4af6-b4c7-3d915e9e65ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'LogisticRegression()' generalization scores:\n",
      "Weighted f1: 0.426 +/- 0.015\n",
      "Cohen Kappa: 0.437 +/- 0.019\n",
      "Adjacent Accuracy: 0.832 +/- 0.009\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.41609777106229123\n",
      "{'C': 0.11938997108268634, 'max_iter': 4097, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 2 with a best result of 0.41454042634241617\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 3 with a best result of 0.4157694840228783\n",
      "{'C': 0.015478974396671013, 'max_iter': 1866, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 4 with a best result of 0.4144613865885335\n",
      "{'C': 0.7475987911298642, 'max_iter': 2358, 'solver': 'newton-cg'}\n",
      "Best hyperparameters for fold 5 with a best result of 0.4199091692721623\n",
      "{'C': 0.11938997108268634, 'max_iter': 4097, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "cv_results_LR_full = randomized_search_and_cv(model_LR, param_distributions, preprocess_dataframe(data_add_features), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c594a3-545f-4768-be8e-a44933b365bb",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cbc387b-3a3f-49d5-9ce9-035b63d36791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_HGBC = HistGradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "837958b8-89d6-452e-8ae7-f36cc3b7fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions_HGBC = {\n",
    "    \"learning_rate\": loguniform(0.001, 2),\n",
    "    \"max_iter\": loguniform_int(10, 1000),\n",
    "    \"max_leaf_nodes\": loguniform_int(2, 100),\n",
    "    \"max_depth\": loguniform_int(2, 50),\n",
    "    \"max_bins\": loguniform_int(2, 100),\n",
    "    \"l2_regularization\": loguniform(0.0001, 0.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "40f3fe03-fb47-403f-9bed-eed2c00011d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'HistGradientBoostingClassifier()' generalization scores:\n",
      "Weighted f1: 0.428 +/- 0.008\n",
      "Cohen Kappa: 0.411 +/- 0.011\n",
      "Adjacent Accuracy: 0.825 +/- 0.006\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.40994411753210735\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 2 with a best result of 0.41449792675075126\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 3 with a best result of 0.41350562774139005\n",
      "{'l2_regularization': 0.00023109044472742628, 'learning_rate': 0.024552114543090666, 'max_bins': 84, 'max_depth': 11, 'max_iter': 241, 'max_leaf_nodes': 6}\n",
      "Best hyperparameters for fold 4 with a best result of 0.41195800553360185\n",
      "{'l2_regularization': 0.00023109044472742628, 'learning_rate': 0.024552114543090666, 'max_bins': 84, 'max_depth': 11, 'max_iter': 241, 'max_leaf_nodes': 6}\n",
      "Best hyperparameters for fold 5 with a best result of 0.41264019924864986\n",
      "{'l2_regularization': 0.00023109044472742628, 'learning_rate': 0.024552114543090666, 'max_bins': 84, 'max_depth': 11, 'max_iter': 241, 'max_leaf_nodes': 6}\n"
     ]
    }
   ],
   "source": [
    "cv_results_HGBC_data = randomized_search_and_cv(model_HGBC, param_distributions_HGBC, preprocess_dataframe(data), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "7f73fadd-2c2f-4faa-9218-717d3ed137b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'HistGradientBoostingClassifier()' generalization scores:\n",
      "Weighted f1: 0.435 +/- 0.003\n",
      "Cohen Kappa: 0.442 +/- 0.021\n",
      "Adjacent Accuracy: 0.836 +/- 0.008\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.4093971740378257\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 2 with a best result of 0.41025388113630223\n",
      "{'l2_regularization': 0.00023109044472742628, 'learning_rate': 0.024552114543090666, 'max_bins': 84, 'max_depth': 11, 'max_iter': 241, 'max_leaf_nodes': 6}\n",
      "Best hyperparameters for fold 3 with a best result of 0.41312499098101485\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 4 with a best result of 0.41210720019525093\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 5 with a best result of 0.4093085194944207\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "cv_results_HGBC_base = randomized_search_and_cv(model_HGBC, param_distributions_HGBC, preprocess_dataframe(data[base_feats_cat+base_feats_num]), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "af7c5bdd-7190-4a62-a03d-6954eb1709f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'HistGradientBoostingClassifier()' generalization scores:\n",
      "Weighted f1: 0.431 +/- 0.016\n",
      "Cohen Kappa: 0.432 +/- 0.027\n",
      "Adjacent Accuracy: 0.830 +/- 0.008\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.4157359701513313\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 2 with a best result of 0.42000243902431655\n",
      "{'l2_regularization': 0.21957037777542873, 'learning_rate': 0.07829484945755741, 'max_bins': 2, 'max_depth': 14, 'max_iter': 45, 'max_leaf_nodes': 15}\n",
      "Best hyperparameters for fold 3 with a best result of 0.4221289313308582\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n",
      "Best hyperparameters for fold 4 with a best result of 0.41673924662812933\n",
      "{'l2_regularization': 0.00023109044472742628, 'learning_rate': 0.024552114543090666, 'max_bins': 84, 'max_depth': 11, 'max_iter': 241, 'max_leaf_nodes': 6}\n",
      "Best hyperparameters for fold 5 with a best result of 0.42126190931996055\n",
      "{'l2_regularization': 0.02853359428016051, 'learning_rate': 0.050080009587496074, 'max_bins': 80, 'max_depth': 13, 'max_iter': 640, 'max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "cv_results_HGBC_full = randomized_search_and_cv(model_HGBC, param_distributions_HGBC, preprocess_dataframe(data_add_features), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a394b16-47b8-4659-a96b-80229f808d55",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12a648a4-2535-4cae-8255-f54cf65485f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(use_label_encoder=False,error_score='raise', n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4af7247e-cdaa-4fa6-ba79-c1304386b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions_xgb = {\n",
    "    \"n_estimators\": loguniform_int(10, 5000),\n",
    "    \"max_depth\": loguniform_int(1, 20),\n",
    "    \"learning_rate\": loguniform(0.0001, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "930efbb1-02e9-4f35-ac07-64958030ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, error_score='raise', gamma=None,\n",
      "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=3, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=None)' generalization scores:\n",
      "Weighted f1: 0.430 +/- 0.005\n",
      "Cohen Kappa: 0.406 +/- 0.023\n",
      "Adjacent Accuracy: 0.825 +/- 0.006\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.40873389830669626\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 2 with a best result of 0.4094008455452129\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 3 with a best result of 0.4064086954852075\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 4 with a best result of 0.40896648812601877\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 5 with a best result of 0.4107501734165952\n",
      "{'learning_rate': 0.014297724879798386, 'max_depth': 3, 'n_estimators': 706}\n"
     ]
    }
   ],
   "source": [
    "cv_results_xgb_data = randomized_search_and_cv(model_xgb, param_distributions_xgb, preprocess_dataframe(data), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d744a8-de7e-446c-af9b-004f0a39ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, error_score='raise', gamma=None,\n",
      "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=3, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=None)' generalization scores:\n",
      "Weighted f1: 0.437 +/- 0.013\n",
      "Cohen Kappa: 0.432 +/- 0.031\n",
      "Adjacent Accuracy: 0.836 +/- 0.007\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.40134390726365066\n",
      "{'learning_rate': 0.014297724879798386, 'max_depth': 3, 'n_estimators': 706}\n",
      "Best hyperparameters for fold 2 with a best result of 0.4081830940234482\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 3 with a best result of 0.4108525021824553\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 4 with a best result of 0.40406171130600044\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 5 with a best result of 0.4111578053644586\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n"
     ]
    }
   ],
   "source": [
    "cv_results_xgb_base = randomized_search_and_cv(model_xgb, param_distributions_xgb, preprocess_dataframe(data[base_feats_cat+base_feats_num]), target_cat, scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b14ed0b0-62b6-4ac3-81bc-b111f016c950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, error_score='raise', gamma=None,\n",
      "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=3, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, use_label_encoder=False,\n",
      "              validate_parameters=None, verbosity=None)' generalization scores:\n",
      "Weighted f1: 0.428 +/- 0.015\n",
      "Cohen Kappa: 0.421 +/- 0.023\n",
      "Adjacent Accuracy: 0.830 +/- 0.004\n",
      "\n",
      "Best hyperparameters for fold 1 with a best result of 0.4101007027061435\n",
      "{'learning_rate': 0.014297724879798386, 'max_depth': 3, 'n_estimators': 706}\n",
      "Best hyperparameters for fold 2 with a best result of 0.4132869438679525\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 3 with a best result of 0.41236433787537763\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 4 with a best result of 0.4141320382555086\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n",
      "Best hyperparameters for fold 5 with a best result of 0.4116558296413902\n",
      "{'learning_rate': 0.04806954824961597, 'max_depth': 3, 'n_estimators': 322}\n"
     ]
    }
   ],
   "source": [
    "cv_results_xgb_full = randomized_search_and_cv(model_xgb, param_distributions_xgb, preprocess_dataframe(data_add_features), target_cat, scoring)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "xgboost_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
